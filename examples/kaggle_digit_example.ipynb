{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "99% Accuracy in 30 Minutes\n",
    "==============\n",
    "\n",
    "Using the following code, I was able to achieve a score 99.071% on the Kaggle digit recognizer challenge, with a total training time of roughly 30 minutes on my Core i5 MacBook Pro. As of writing this, I'm sitting in 47th place overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyneural\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import scipy.ndimage as nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the training data and transform it into usable numpy arrays\n",
    "# Note: you may need to change the path to the data\n",
    "training_set = pd.read_csv('~/kaggle/digits/train.csv')\n",
    "labels = np.array(training_set)[:, 0]\n",
    "features = np.array(training_set)[:, 1:].astype(float) / 255.0\n",
    "\n",
    "n_rows = features.shape[0]\n",
    "n_features = features.shape[1]\n",
    "n_labels = 10\n",
    "n_steps = 5\n",
    "\n",
    "labels_expanded = np.zeros((n_rows, n_labels))\n",
    "for i in xrange(n_rows):\n",
    "    labels_expanded[i][labels[i]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expanding the training set is the key to success\n",
    "---------------------------------------------\n",
    "\n",
    "I had managed to get over 98% accuracy on the test set with PyNeural in the past, but my ability to crack 99% was thanks to insight gained from [this excellent blog post](http://nicklocascio.com/neural-net-mnist-kaggle/).\n",
    "\n",
    "The MNIST training set supplied in the Kaggle competition is, by computer vision standards, relatively small, so overfitting is a big issue. Nick Locascio points out in his blog post above that you can greatly, and almost trivially, expand the training set using simple transformations of the given training examples.\n",
    "\n",
    "Nick uses vertical and horizontal shifts, or \"nudges\", and rotations to multiply the number of training examples. I used the `scipy.ndimage` to perform these transformations, and further expanded on these by adding horizontal and vertical scalings as well. \n",
    "\n",
    "You could increase the training set further by repeating these transformations with different degrees of shifting, rotation, and scaling; I would imagine there is some point of marginal returns, but I don't actually know where that is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# transform the training set into 42000 28x28 pixel \"images\"\n",
    "ims = features.reshape((42000 , 28, 28))\n",
    "\n",
    "# shift each image down, up, right, and left, respectively, by 2 pixels\n",
    "dshift = nd.shift(ims, (0, 2, 0), order=0).reshape((42000, 784))\n",
    "ushift = nd.shift(ims, (0, -2, 0), order=0).reshape((42000, 784))\n",
    "rshift = nd.shift(ims, (0, 0, 2), order=0).reshape((42000, 784))\n",
    "lshift = nd.shift(ims, (0, 0, -2), order=0).reshape((42000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# rotate each image by 15 degrees both counter-clockwise and clockwise\n",
    "lrotate = nd.rotate(ims, 15, axes=(1,2), reshape=False, prefilter=False).reshape((42000, 784))\n",
    "rrotate = nd.rotate(ims, -15, axes=(1,2), reshape=False, prefilter=False).reshape((42000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# scale each image by 1.5 in both the vertical and horizontal directions\n",
    "vscale = nd.zoom(ims, (1, 1.5, 1), order=0, prefilter=False)[:, 7:-7, :].reshape((42000, 784))\n",
    "hscale = nd.zoom(ims, (1, 1, 1.5), order=0, prefilter=False)[:, :, 7:-7].reshape((42000, 784))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# combine each of the transformations along with the original training set into a super set\n",
    "new_features = np.vstack((features, dshift, ushift, rshift, lshift, lrotate, rrotate, vscale, hscale))\n",
    "new_labels = np.vstack(9 * [labels_expanded])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Neural Net\n",
    "----------------------\n",
    "\n",
    "To achieve my results, I used a neural network with two hidden layers of 400 nodes each and trained it over 65 epochs using mini-batches of size 100, a learning rate of 0.01, no L2 regularization, and no decay of the learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nn = pyneural.NeuralNet([784, 400, 400, 10])\n",
    "nn.train(new_features, new_labels, 65, 100, 0.01, 0.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# check the accuracy on the training set\n",
    "preds = nn.predict_label(new_features)\n",
    "correct = np.sum(preds == np.hstack(9 * [labels]))        \n",
    "print \"%f%% percent correct \" % (100.0 * correct / new_features.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the test set and make our predictions\n",
    "test_set = pd.read_csv('~/kaggle/digits/test.csv')\n",
    "test_features = np.array(test_set).astype(float) / 255.0\n",
    "test_preds = nn.predict_label(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save our predictions to a csv file\n",
    "df = pd.DataFrame({'ImageId': np.arange(1, len(test_preds) + 1), 'Label': test_preds})\n",
    "df.to_csv('/Users/taylor/kaggle/digits/exp_set4.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
